"""
Write your unit tests here. Some tests to include are listed below.
This is not an exhaustive list.

- check that prediction is working correctly
- check that your loss function is being calculated correctly
- check that your gradient is being calculated correctly
- check that your weights update during training
"""
import matplotlib.pyplot as plt
# Imports
import pytest
import numpy as np
from regression import logreg as lr
from regression import utils
# (you will probably need to import more things here)

def test_prediction():
	# parameters
	n_obs = 100
	n_obs_train = 60
	m = .1
	dispersion = 0.1

	# initialize objects
	lreg = lr.LogisticRegressor(1, learning_rate=1, tol=.01, max_iter=400)

	# generate data
	x_true = np.array(np.arange(0,1,1/n_obs))
	x_true = x_true.reshape(n_obs, 1)

	y_true = np.array([np.round(i + m + 0.4*np.sin(100*i) * dispersion) for i in x_true])

	#plt.scatter(x_true, y_true)
	#plt.show()

	lreg.W = np.array([20,-8])
	x_true = np.hstack([x_true, np.ones((x_true.shape[0], 1))])

	predicted_benchmark = [0.0003353501304664781, 0.00040956716498605043, 0.0005002011070795643, 0.000610879359434401, 0.000746028833836697, 0.0009110511944006454, 0.0011125360328603216, 0.0013585199504289591, 0.0016588010801744215, 0.002025320389049882, 0.0024726231566347743, 0.003018416324708424, 0.003684239899435989, 0.004496273160941178, 0.005486298899450409, 0.0066928509242848554, 0.008162571153159897, 0.009951801866904324, 0.012128434984274237, 0.014774031693273055, 0.01798620996209156, 0.021881270936130476, 0.026596993576865863, 0.03229546469845053, 0.039165722796764356, 0.04742587317756678, 0.057324175898868755, 0.06913842034334684, 0.08317269649392241, 0.09975048911968513, 0.11920292202211755, 0.14185106490048782, 0.16798161486607557, 0.19781611144141834, 0.23147521650098246, 0.26894142136999527, 0.3100255188723874, 0.35434369377420466, 0.40131233988754794, 0.4501660026875223, 0.5, 0.5498339973124782, 0.5986876601124521, 0.6456563062257954, 0.6899744811276126, 0.7310585786300049, 0.7685247834990179, 0.8021838885585818, 0.8320183851339245, 0.8581489350995123, 0.8807970779778823, 0.9002495108803148, 0.9168273035060777, 0.9308615796566533, 0.9426758241011313, 0.9525741268224334, 0.9608342772032357, 0.9677045353015495, 0.973403006423134, 0.9781187290638694, 0.9820137900379085, 0.9852259683067269, 0.9878715650157257, 0.9900481981330957, 0.9918374288468401, 0.9933071490757153, 0.9945137011005495, 0.9955037268390589, 0.9963157601005641, 0.9969815836752917, 0.9975273768433653, 0.9979746796109501, 0.9983411989198255, 0.9986414800495711, 0.9988874639671398, 0.9990889488055994, 0.9992539711661633, 0.9993891206405656, 0.9994997988929205, 0.9995904328350139, 0.9996646498695336, 0.9997254218438986, 0.9997751832297667, 0.9998159280950366, 0.9998492896419403, 0.9998766054240137, 0.9998989708060922, 0.9999172827771484, 0.9999322758503804, 0.9999445514752772, 0.9999546021312976, 0.9999628310628971, 0.9999695684430994, 0.9999750846110607, 0.9999796009127201, 0.999983298578152, 0.9999863259909154, 0.999988804640495, 0.9999908339962802, 0.9999924954984029]

	predicted_labels = lreg.make_prediction(x_true)

	tolerance = 0.00001
	comparisonbools = [abs(predicted_labels[x]-predicted_benchmark[x]) < tolerance for x in range(n_obs)]

	assert all(comparisonbools), "prediction failed"

def test_loss_function():

	data = utils.loadDataset()
	x_true = data[0]
	y_true = data[1]

	n = x_true.shape[0]

	n_obs_train = 60

	print("")
	#print("---")
	#print(x_true.shape)
	#print(x_true[0:n_obs_train].shape)
	#print(y_true[0:n_obs_train].shape)
	#print(y_true[n_obs_train:])

	lreg = lr.LogisticRegressor(6, learning_rate = 1, tol = .001, max_iter=400)
	lreg.train_model(x_true[0:n_obs_train], y_true[0:n_obs_train], x_true[n_obs_train:], y_true[n_obs_train:])

	#print(lreg.loss_hist_val)

	benchmark_rlv = [-16.961916986006337, -16.961916987439427, -16.961916988713106, -16.96191698930091, -16.961916991372547, -16.961916991562312]

	tolerance = 0.00001
	comparisonbools = [abs(lreg.loss_hist_val[x]-benchmark_rlv[x]) < tolerance for x in range(len(benchmark_rlv))]

	#assert all(comparisonbools), "loss calculation failed"

def test_gradient():
	pass

def test_training():
	pass